{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91531, 33)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "train_df.drop(train_df[train_df.adr < 0].index, inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89424, 33)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature transform\n",
    "train_df['stays'] = train_df.apply(lambda row: row.stays_in_weekend_nights + row.stays_in_week_nights, axis=1)\n",
    "train_df['expected_cost'] = train_df.apply(lambda row: row.adr * row.stays, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the target variable from the training set\n",
    "label = train_df['is_canceled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = ['lead_time', 'stays', 'stays_in_weekend_nights', 'stays_in_week_nights',\\\n",
    "               'adults', 'children', 'babies', 'previous_cancellations',\\\n",
    "               'previous_bookings_not_canceled', 'booking_changes', 'days_in_waiting_list',\\\n",
    "               'adr', 'expected_cost', 'required_car_parking_spaces', 'total_of_special_requests'\n",
    "              ]\n",
    "categoryCols = ['hotel', 'arrival_date_year', 'arrival_date_month',\\\n",
    "                'arrival_date_week_number', 'arrival_date_day_of_month', 'meal',\\\n",
    "                'country', 'market_segment', 'distribution_channel',\\\n",
    "                'is_repeated_guest', 'reserved_room_type', 'assigned_room_type',\\\n",
    "                'deposit_type', 'customer_type'\n",
    "               ]\n",
    "featureCols = numericCols + categoryCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer\n",
    "\n",
    "# Transforming the categoric columns\n",
    "cat_si_step = ('si', SimpleImputer(strategy='constant', fill_value='MISSING'))\n",
    "cat_ohe_step = ('ohe', OneHotEncoder(sparse=True, handle_unknown='ignore'))\n",
    "cat_steps = [cat_si_step, cat_ohe_step]\n",
    "cat_pipe = Pipeline(cat_steps)\n",
    "\n",
    "cat_transformers = [('cat', cat_pipe, categoryCols)]\n",
    "ct = ColumnTransformer(transformers=cat_transformers)\n",
    "\n",
    "train_cat_transformed = ct.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_City Hotel', 'x0_Resort Hotel', 'x1_2015', 'x1_2016',\n",
       "       'x1_2017', 'x2_April', 'x2_August', 'x2_December', 'x2_February',\n",
       "       'x2_January', 'x2_July', 'x2_June', 'x2_March', 'x2_May',\n",
       "       'x2_November', 'x2_October', 'x2_September', 'x3_1', 'x3_2',\n",
       "       'x3_3', 'x3_4', 'x3_5', 'x3_6', 'x3_7', 'x3_8', 'x3_9', 'x3_10',\n",
       "       'x3_11', 'x3_12', 'x3_13', 'x3_14', 'x3_15', 'x3_16', 'x3_17',\n",
       "       'x3_18', 'x3_19', 'x3_20', 'x3_21', 'x3_22', 'x3_23', 'x3_24',\n",
       "       'x3_25', 'x3_26', 'x3_27', 'x3_28', 'x3_29', 'x3_30', 'x3_31',\n",
       "       'x3_32', 'x3_33', 'x3_34', 'x3_35', 'x3_36', 'x3_37', 'x3_38',\n",
       "       'x3_39', 'x3_40', 'x3_41', 'x3_42', 'x3_43', 'x3_44', 'x3_45',\n",
       "       'x3_46', 'x3_47', 'x3_48', 'x3_49', 'x3_50', 'x3_51', 'x3_52',\n",
       "       'x3_53', 'x4_1', 'x4_2', 'x4_3', 'x4_4', 'x4_5', 'x4_6', 'x4_7',\n",
       "       'x4_8', 'x4_9', 'x4_10', 'x4_11', 'x4_12', 'x4_13', 'x4_14',\n",
       "       'x4_15', 'x4_16', 'x4_17', 'x4_18', 'x4_19', 'x4_20', 'x4_21',\n",
       "       'x4_22', 'x4_23', 'x4_24', 'x4_25', 'x4_26', 'x4_27', 'x4_28',\n",
       "       'x4_29', 'x4_30', 'x4_31', 'x5_BB', 'x5_FB', 'x5_HB', 'x5_SC',\n",
       "       'x5_Undefined', 'x6_ABW', 'x6_AGO', 'x6_AIA', 'x6_ALB', 'x6_AND',\n",
       "       'x6_ARE', 'x6_ARG', 'x6_ARM', 'x6_ASM', 'x6_ATA', 'x6_AUS',\n",
       "       'x6_AUT', 'x6_AZE', 'x6_BDI', 'x6_BEL', 'x6_BEN', 'x6_BFA',\n",
       "       'x6_BGD', 'x6_BGR', 'x6_BHR', 'x6_BIH', 'x6_BLR', 'x6_BOL',\n",
       "       'x6_BRA', 'x6_BRB', 'x6_BWA', 'x6_CAF', 'x6_CHE', 'x6_CHL',\n",
       "       'x6_CHN', 'x6_CIV', 'x6_CMR', 'x6_CN', 'x6_COL', 'x6_COM',\n",
       "       'x6_CPV', 'x6_CRI', 'x6_CUB', 'x6_CYM', 'x6_CYP', 'x6_CZE',\n",
       "       'x6_DEU', 'x6_DMA', 'x6_DNK', 'x6_DOM', 'x6_DZA', 'x6_ECU',\n",
       "       'x6_EGY', 'x6_ESP', 'x6_EST', 'x6_ETH', 'x6_FIN', 'x6_FRA',\n",
       "       'x6_GAB', 'x6_GBR', 'x6_GEO', 'x6_GGY', 'x6_GHA', 'x6_GIB',\n",
       "       'x6_GLP', 'x6_GNB', 'x6_GRC', 'x6_GTM', 'x6_GUY', 'x6_HKG',\n",
       "       'x6_HND', 'x6_HRV', 'x6_HUN', 'x6_IDN', 'x6_IMN', 'x6_IND',\n",
       "       'x6_IRL', 'x6_IRN', 'x6_IRQ', 'x6_ISL', 'x6_ISR', 'x6_ITA',\n",
       "       'x6_JAM', 'x6_JEY', 'x6_JOR', 'x6_JPN', 'x6_KAZ', 'x6_KEN',\n",
       "       'x6_KHM', 'x6_KNA', 'x6_KOR', 'x6_KWT', 'x6_LBN', 'x6_LBY',\n",
       "       'x6_LCA', 'x6_LIE', 'x6_LKA', 'x6_LTU', 'x6_LUX', 'x6_LVA',\n",
       "       'x6_MAC', 'x6_MAR', 'x6_MCO', 'x6_MDG', 'x6_MDV', 'x6_MEX',\n",
       "       'x6_MISSING', 'x6_MKD', 'x6_MLI', 'x6_MLT', 'x6_MMR', 'x6_MNE',\n",
       "       'x6_MOZ', 'x6_MUS', 'x6_MWI', 'x6_MYS', 'x6_NAM', 'x6_NGA',\n",
       "       'x6_NIC', 'x6_NLD', 'x6_NOR', 'x6_NZL', 'x6_OMN', 'x6_PAK',\n",
       "       'x6_PAN', 'x6_PER', 'x6_PHL', 'x6_PLW', 'x6_POL', 'x6_PRI',\n",
       "       'x6_PRT', 'x6_PRY', 'x6_PYF', 'x6_QAT', 'x6_ROU', 'x6_RUS',\n",
       "       'x6_RWA', 'x6_SAU', 'x6_SEN', 'x6_SGP', 'x6_SLV', 'x6_SMR',\n",
       "       'x6_SRB', 'x6_STP', 'x6_SUR', 'x6_SVK', 'x6_SVN', 'x6_SWE',\n",
       "       'x6_SYC', 'x6_SYR', 'x6_TGO', 'x6_THA', 'x6_TJK', 'x6_TMP',\n",
       "       'x6_TUN', 'x6_TUR', 'x6_TWN', 'x6_TZA', 'x6_UGA', 'x6_UKR',\n",
       "       'x6_URY', 'x6_USA', 'x6_UZB', 'x6_VEN', 'x6_VGB', 'x6_VNM',\n",
       "       'x6_ZAF', 'x6_ZMB', 'x6_ZWE', 'x7_Aviation', 'x7_Complementary',\n",
       "       'x7_Corporate', 'x7_Direct', 'x7_Groups', 'x7_Offline TA/TO',\n",
       "       'x7_Online TA', 'x7_Undefined', 'x8_Corporate', 'x8_Direct',\n",
       "       'x8_GDS', 'x8_TA/TO', 'x8_Undefined', 'x9_0', 'x9_1', 'x10_A',\n",
       "       'x10_B', 'x10_C', 'x10_D', 'x10_E', 'x10_F', 'x10_G', 'x10_H',\n",
       "       'x10_L', 'x10_P', 'x11_A', 'x11_B', 'x11_C', 'x11_D', 'x11_E',\n",
       "       'x11_F', 'x11_G', 'x11_H', 'x11_I', 'x11_K', 'x11_L', 'x11_P',\n",
       "       'x12_No Deposit', 'x12_Non Refund', 'x12_Refundable',\n",
       "       'x13_Contract', 'x13_Group', 'x13_Transient',\n",
       "       'x13_Transient-Party'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the feature names\n",
    "pl = ct.named_transformers_['cat']\n",
    "ohe = pl.named_steps['ohe']\n",
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the numeric columns\n",
    "num_si_step = ('si', SimpleImputer(strategy='median'))\n",
    "num_ss_step = ('ss', StandardScaler())\n",
    "num_steps = [num_si_step, num_ss_step]\n",
    "num_pipe = Pipeline(num_steps)\n",
    "\n",
    "num_transformers = [('num', num_pipe, numericCols)]\n",
    "ct = ColumnTransformer(transformers=num_transformers)\n",
    "\n",
    "train_num_transformed = ct.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining both categorical and numerical column transformations\n",
    "ct = ColumnTransformer(transformers=[('cat', cat_pipe, categoryCols), ('num', num_pipe, numericCols)])\n",
    "train_transformed = ct.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD\n",
    "svd = TruncatedSVD(n_components=60) # best 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr = LogisticRegression(penalty='l2', C=75.0, max_iter=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "#sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "rfe = RFE(estimator=lr, n_features_to_select=5, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8305935766684559"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute pipeline\n",
    "lr_pipe = Pipeline([('transform', ct), ('lr', lr)])\n",
    "lr_pipe.fit(train_df, label)\n",
    "lr_pipe.score(train_df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=1126, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('transform',\n",
       "                                        ColumnTransformer(transformers=[('cat',\n",
       "                                                                         Pipeline(steps=[('si',\n",
       "                                                                                          SimpleImputer(fill_value='MISSING',\n",
       "                                                                                                        strategy='constant')),\n",
       "                                                                                         ('ohe',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['hotel',\n",
       "                                                                          'arrival_date_year',\n",
       "                                                                          'arrival_date_month',\n",
       "                                                                          'arrival_date_week_number',\n",
       "                                                                          'a...\n",
       "                                                                          'previous_cancellations',\n",
       "                                                                          'previous_bookings_not_canceled',\n",
       "                                                                          'booking_changes',\n",
       "                                                                          'days_in_waiting_list',\n",
       "                                                                          'adr',\n",
       "                                                                          'required_car_parking_spaces',\n",
       "                                                                          'total_of_special_requests'])])),\n",
       "                                       ('svd', TruncatedSVD(n_components=3)),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             param_grid={'lr__C': [75.0], 'lr__penalty': ['l2'],\n",
       "                         'svd__n_components': [50, 60],\n",
       "                         'transform__num__si__strategy': ['median']})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1126)\n",
    "cross_val_score(ml_pipe, train_df, label, cv=kf).mean()\n",
    "\n",
    "\n",
    "# Selecting parameters when Grid Searching\n",
    "param_grid = {\n",
    "    'transform__num__si__strategy': ['median'],\n",
    "    #'svd__n_components': [60, 70],\n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__C': [75.0]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(lr_pipe, param_grid, cv=kf)\n",
    "gs.fit(train_df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 75.0, 'lr__penalty': 'l2', 'svd__n_components': 60, 'transform__num__si__strategy': 'median'}\n",
      "0.8225081930052852\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_lr__C  \\\n",
      "0       4.165994      0.046248         0.111351        0.001417          75   \n",
      "1       4.957987      0.173773         0.132769        0.025136          75   \n",
      "\n",
      "  param_lr__penalty param_svd__n_components  \\\n",
      "0                l2                      50   \n",
      "1                l2                      60   \n",
      "\n",
      "  param_transform__num__si__strategy  \\\n",
      "0                             median   \n",
      "1                             median   \n",
      "\n",
      "                                              params  split0_test_score  \\\n",
      "0  {'lr__C': 75.0, 'lr__penalty': 'l2', 'svd__n_c...           0.823237   \n",
      "1  {'lr__C': 75.0, 'lr__penalty': 'l2', 'svd__n_c...           0.825094   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
      "0           0.815962           0.821097           0.824648           0.824921   \n",
      "1           0.816508           0.821589           0.824429           0.824921   \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  \n",
      "0         0.821973        0.003297                2  \n",
      "1         0.822508        0.003257                1  \n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params_)\n",
    "\n",
    "print(gs.best_score_)\n",
    "\n",
    "# Getting all the grid search results in a Pandas DataFrame\n",
    "print(pd.DataFrame(gs.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "'''\n",
    "svc = SVC(C=1.0, kernel='linear', gamma='scale')\n",
    "svc_pipe = Pipeline([('transform', ct), ('svc', svc)])\n",
    "svc_pipe.fit(train_df, label)\n",
    "svc_pipe.score(train_df, label)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "will_be_canceled = lr_pipe.predict(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    63593\n",
       "1    25831\n",
       "Name: will_be_canceled, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will_be_canceled = pd.Series(will_be_canceled)\n",
    "\n",
    "train_df['will_be_canceled'] = will_be_canceled\n",
    "\n",
    "train_df['will_be_canceled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthMap = {'January':'1', 'February':'2', 'March':'3',\\\n",
    "            'April':'4', 'May':'5', 'June':'6',\\\n",
    "            'July':'7', 'August':'8', 'September':'9',\\\n",
    "            'October':'10', 'November':'11', 'December':'12'}\n",
    "def getArrivalDate(row):\n",
    "    return pd.to_datetime(str(row.arrival_date_year) + '-' + monthMap[row.arrival_date_month] + '-' + str(row.arrival_date_day_of_month))\n",
    "\n",
    "def getRevenue(row):\n",
    "    if row.is_canceled:\n",
    "        return 0\n",
    "    return row.expected_cost\n",
    "\n",
    "def predictRevenue(row):\n",
    "    if row.will_be_canceled:\n",
    "        return 0\n",
    "    return row.expected_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post process\n",
    "train_df['arrival_date'] = train_df.apply(getArrivalDate, axis=1)\n",
    "train_df['predicted_revenue'] = train_df.apply(predictRevenue, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by date\n",
    "daily_revenue_df = train_df.groupby(['arrival_date']).agg({'revenue':'sum', 'predicted_revenue':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000]\n",
    "labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "daily_revenue_df['calculated_label'] = pd.cut(daily_revenue_df.revenue, bins=bins,labels=labels)\n",
    "daily_revenue_df['predicted_label'] = pd.cut(daily_revenue_df.predicted_revenue, bins=bins,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "      <th>predicted_revenue</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>calculated_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-01</th>\n",
       "      <td>20317.720355</td>\n",
       "      <td>21151.889054</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-02</th>\n",
       "      <td>16530.645277</td>\n",
       "      <td>19040.399816</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-03</th>\n",
       "      <td>12989.951853</td>\n",
       "      <td>17136.097402</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-04</th>\n",
       "      <td>17488.551606</td>\n",
       "      <td>15065.486549</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-05</th>\n",
       "      <td>19591.458478</td>\n",
       "      <td>20241.138995</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-27</th>\n",
       "      <td>26217.381380</td>\n",
       "      <td>29834.381779</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-28</th>\n",
       "      <td>16185.177703</td>\n",
       "      <td>16927.454674</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-29</th>\n",
       "      <td>24002.255525</td>\n",
       "      <td>27352.011096</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-30</th>\n",
       "      <td>33327.810920</td>\n",
       "      <td>39426.908779</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>36130.595184</td>\n",
       "      <td>41152.181686</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   revenue  predicted_revenue predicted_label calculated_label\n",
       "arrival_date                                                                  \n",
       "2015-07-01    20317.720355       21151.889054               2                2\n",
       "2015-07-02    16530.645277       19040.399816               1                1\n",
       "2015-07-03    12989.951853       17136.097402               1                1\n",
       "2015-07-04    17488.551606       15065.486549               1                1\n",
       "2015-07-05    19591.458478       20241.138995               2                1\n",
       "...                    ...                ...             ...              ...\n",
       "2017-03-27    26217.381380       29834.381779               2                2\n",
       "2017-03-28    16185.177703       16927.454674               1                1\n",
       "2017-03-29    24002.255525       27352.011096               2                2\n",
       "2017-03-30    33327.810920       39426.908779               3                3\n",
       "2017-03-31    36130.595184       41152.181686               4                3\n",
       "\n",
       "[640 rows x 4 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_revenue_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_df = pd.read_csv('train_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = daily_revenue_df.join(train_label_df.set_index('arrival_date'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['calculated_err'] = labels.apply(lambda row: abs(row.calculated_label - row.label), axis=1)\n",
    "labels['err'] = labels.apply(lambda row: abs(row.predicted_label - row.label), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "      <th>predicted_revenue</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>calculated_label</th>\n",
       "      <th>label</th>\n",
       "      <th>calculated_err</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-01</th>\n",
       "      <td>20317.720355</td>\n",
       "      <td>21151.889054</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-02</th>\n",
       "      <td>16530.645277</td>\n",
       "      <td>19040.399816</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-03</th>\n",
       "      <td>12989.951853</td>\n",
       "      <td>17136.097402</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-04</th>\n",
       "      <td>17488.551606</td>\n",
       "      <td>15065.486549</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-05</th>\n",
       "      <td>19591.458478</td>\n",
       "      <td>20241.138995</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-27</th>\n",
       "      <td>26217.381380</td>\n",
       "      <td>29834.381779</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-28</th>\n",
       "      <td>16185.177703</td>\n",
       "      <td>16927.454674</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-29</th>\n",
       "      <td>24002.255525</td>\n",
       "      <td>27352.011096</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-30</th>\n",
       "      <td>33327.810920</td>\n",
       "      <td>39426.908779</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>36130.595184</td>\n",
       "      <td>41152.181686</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   revenue  predicted_revenue predicted_label  \\\n",
       "arrival_date                                                    \n",
       "2015-07-01    20317.720355       21151.889054               2   \n",
       "2015-07-02    16530.645277       19040.399816               1   \n",
       "2015-07-03    12989.951853       17136.097402               1   \n",
       "2015-07-04    17488.551606       15065.486549               1   \n",
       "2015-07-05    19591.458478       20241.138995               2   \n",
       "...                    ...                ...             ...   \n",
       "2017-03-27    26217.381380       29834.381779               2   \n",
       "2017-03-28    16185.177703       16927.454674               1   \n",
       "2017-03-29    24002.255525       27352.011096               2   \n",
       "2017-03-30    33327.810920       39426.908779               3   \n",
       "2017-03-31    36130.595184       41152.181686               4   \n",
       "\n",
       "             calculated_label  label  calculated_err  err  \n",
       "arrival_date                                               \n",
       "2015-07-01                  2    2.0             0.0  0.0  \n",
       "2015-07-02                  1    1.0             0.0  0.0  \n",
       "2015-07-03                  1    1.0             0.0  0.0  \n",
       "2015-07-04                  1    1.0             0.0  0.0  \n",
       "2015-07-05                  1    1.0             0.0  1.0  \n",
       "...                       ...    ...             ...  ...  \n",
       "2017-03-27                  2    2.0             0.0  0.0  \n",
       "2017-03-28                  1    1.0             0.0  0.0  \n",
       "2017-03-29                  2    2.0             0.0  0.0  \n",
       "2017-03-30                  3    3.0             0.0  0.0  \n",
       "2017-03-31                  3    3.0             0.0  1.0  \n",
       "\n",
       "[640 rows x 7 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n",
      "196.0\n"
     ]
    }
   ],
   "source": [
    "total_calculated_error = labels['calculated_err'].sum(axis = 0, skipna = True)\n",
    "total_predicted_error = labels['err'].sum(axis = 0, skipna = True)\n",
    "print(total_calculated_error)\n",
    "print(total_predicted_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    627\n",
       "1.0     13\n",
       "Name: calculated_err, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['calculated_err'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    453\n",
       "1.0    180\n",
       "2.0      6\n",
       "4.0      1\n",
       "Name: err, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['err'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
