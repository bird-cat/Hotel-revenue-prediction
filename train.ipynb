{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, confusion_matrix, log_loss\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression, SGDRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "raw_train_df = pd.read_csv(\"train.csv\")\n",
    "raw_train_label_df = pd.read_csv('train_label.csv')\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation set and training set\n",
    "dates = raw_train_df.arrival_date.unique()\n",
    "train_indices, val_indices = train_test_split(dates, test_size=0.3)\n",
    "train_df = raw_train_df.set_index('arrival_date').loc[train_indices, :]\n",
    "val_df = raw_train_df.set_index('arrival_date').loc[val_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=False, inplace=True)\n",
    "val_df.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer\n",
    "\n",
    "# Transforming the categoric columns\n",
    "cat_si_step = ('si', SimpleImputer(strategy='constant', fill_value='MISSING'))\n",
    "cat_ohe_step = ('ohe', OneHotEncoder(sparse=True, handle_unknown='ignore'))\n",
    "cat_steps = [cat_si_step, cat_ohe_step]\n",
    "cat_pipe = Pipeline(cat_steps)\n",
    "\n",
    "# Transforming the numeric columns\n",
    "num_si_step = ('si', SimpleImputer(strategy='median'))\n",
    "num_ss_step = ('ss', StandardScaler())\n",
    "num_steps = [num_si_step, num_ss_step]\n",
    "num_pipe = Pipeline(num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Predict ADR by regression\n",
    "# Determine features\n",
    "adr_numericCols = ['lead_time', 'arrival_date_year', 'stays', 'stays_in_weekend_nights', 'stays_in_week_nights',\\\n",
    "               'adults', 'children', 'babies', 'persons', 'previous_cancellations',\\\n",
    "               'previous_bookings_not_canceled', 'booking_changes', 'days_in_waiting_list',\\\n",
    "               'required_car_parking_spaces', 'total_of_special_requests'\n",
    "              ]\n",
    "adr_categoricCols = ['hotel', 'arrival_date_month',\\\n",
    "                'arrival_date_week_number', 'arrival_date_day_of_month', 'meal',\\\n",
    "                'country', 'market_segment', 'distribution_channel',\\\n",
    "                'is_repeated_guest', 'reserved_room_type', 'assigned_room_type',\\\n",
    "                'deposit_type', 'customer_type', 'agent'\n",
    "               ]\n",
    "\n",
    "adr_featureCols = adr_numericCols + adr_categoricCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwill_be_canceled = predict_canceled_proba(gbc_pipe, train_df)\\ntrain_df['will_be_canceled'] = will_be_canceled\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "will_be_canceled = predict_canceled_proba(gbc_pipe, train_df)\n",
    "train_df['will_be_canceled'] = will_be_canceled\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_train = train_df[adr_featureCols]\n",
    "adr_val = val_df[adr_featureCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining both categorical and numerical column transformations\n",
    "adr_ct = ColumnTransformer(transformers=[('cat', cat_pipe, adr_categoricCols), ('num', num_pipe, adr_numericCols)])\n",
    "adr_train_transformed = adr_ct.fit_transform(adr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features =  580\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the feature names\n",
    "cat_transformers = [('cat', cat_pipe, adr_categoricCols)]\n",
    "cat_ct = ColumnTransformer(transformers=cat_transformers)\n",
    "train_cat_transformed = cat_ct.fit_transform(train_df)\n",
    "\n",
    "num_transformers = [('num', num_pipe, adr_numericCols)]\n",
    "num_ct = ColumnTransformer(transformers=num_transformers)\n",
    "train_num_transformed = num_ct.fit_transform(train_df)\n",
    "\n",
    "cat_pl = cat_ct.named_transformers_['cat']\n",
    "ohe = cat_pl.named_steps['ohe']\n",
    "transformed_feature_names = list(ohe.get_feature_names()) + adr_numericCols\n",
    "print(\"Total number of features = \", len(transformed_feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "adr_sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "adr_svd = TruncatedSVD(n_components=30) # best 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "ridge = Ridge(alpha=1.0/(2*100), max_iter=10000) # alpha = 1 / 2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# feature transformation\n",
    "poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Build ridge pipeline\n",
    "ridge_pipe = Pipeline([('adr_transform', adr_ct), ('adr_svd', adr_svd), ('poly', poly), ('ridge', ridge)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.606102430361219\n",
      "0.6599906576605303\n",
      "1034.7022239340704\n",
      "698.932785860866\n"
     ]
    }
   ],
   "source": [
    "# Execute ridge pipeline\n",
    "ridge_pipe.fit(adr_train, train_df['adr'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(ridge_pipe.score(adr_train, train_df['adr']))\n",
    "print(ridge_pipe.score(adr_val, val_df['adr']))\n",
    "\n",
    "# Mean squared errors\n",
    "print(mean_squared_error(ridge_pipe.predict(adr_train), train_df['adr']))\n",
    "print(mean_squared_error(ridge_pipe.predict(adr_val), val_df['adr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# SVR\n",
    "rbf_feature = Nystroem(gamma=10**(-1.5), n_components=600, random_state=1126)\n",
    "sgdreg = SGDRegressor(loss='epsilon_insensitive', alpha=10**(-11), max_iter=10000)\n",
    "\n",
    "sgd_pipe = Pipeline([('adr_transform', adr_ct), ('rbf', rbf_feature), ('sgdreg', sgdreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38272605380374847\n",
      "0.45698674243912296\n",
      "1591.1612936139725\n",
      "1179.9846833209801\n"
     ]
    }
   ],
   "source": [
    "# Execute svr pipeline\n",
    "sgd_pipe.fit(adr_train, train_df['adr'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(sgd_pipe.score(adr_train, train_df['adr']))\n",
    "print(sgd_pipe.score(adr_val, val_df['adr']))\n",
    "\n",
    "# Mean squared errors\n",
    "print(mean_squared_error(sgd_pipe.predict(adr_train), train_df['adr']))\n",
    "print(mean_squared_error(sgd_pipe.predict(adr_val), val_df['adr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting regressor\n",
    "gbreg = GradientBoostingRegressor(loss='huber',\n",
    "                                  alpha=0.9,\n",
    "                                  validation_fraction=0.2,\n",
    "                                  n_iter_no_change=5,\n",
    "                                  tol=0.005,\n",
    "                                  max_depth=4,\n",
    "                                  n_estimators=10000,\n",
    "                                  random_state=1126,\n",
    "                                  warm_start=True)\n",
    "gbreg_pipe = Pipeline([('adr_transform', adr_ct), ('gbreg', gbreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7161300645462938\n",
      "0.8125832790070624\n",
      "744.780177956058\n",
      "397.0577868712073\n"
     ]
    }
   ],
   "source": [
    "# Execute gradient boosting pipeline\n",
    "gbreg_pipe.fit(adr_train, train_df['adr'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(gbreg_pipe.score(adr_train, train_df['adr']))\n",
    "print(gbreg_pipe.score(adr_val, val_df['adr']))\n",
    "\n",
    "# Mean squared errors\n",
    "print(mean_squared_error(gbreg_pipe.predict(adr_train), train_df['adr']))\n",
    "print(mean_squared_error(gbreg_pipe.predict(adr_val), val_df['adr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost regressor\n",
    "xgbreg = XGBRegressor(booster='gbtree',\n",
    "                      learning_rate=0.01,\n",
    "                      n_estimators=2000,\n",
    "                      min_child_weight=5,\n",
    "                      subsample=0.8,\n",
    "                      colsample_bytree:0.8,\n",
    "                      max_depth=3,\n",
    "                      gamma=0.05,\n",
    "                      random_state=1126,\n",
    "                      n_jobs=4)\n",
    "xgbreg_pipe = Pipeline([('adr_transform', adr_ct), ('xgbreg', xgbreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6607253676806282\n",
      "0.7438344215068012\n",
      "890.1436519895433\n",
      "542.7079138415021\n"
     ]
    }
   ],
   "source": [
    "# Execute gradient boosting pipeline\n",
    "xgbreg_pipe.fit(adr_train, train_df['adr'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(xgbreg_pipe.score(adr_train, train_df['adr']))\n",
    "print(xgbreg_pipe.score(adr_val, val_df['adr']))\n",
    "\n",
    "# Mean squared errors\n",
    "print(mean_squared_error(xgbreg_pipe.predict(adr_train), train_df['adr']))\n",
    "print(mean_squared_error(xgbreg_pipe.predict(adr_val), val_df['adr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1126)\n",
    "\n",
    "# Selecting parameters when Grid Searching\n",
    "param_grid = {\n",
    "    'xgbreg__n_estimators': [1000, 2000, 5000],\n",
    "    'xgbreg__objective': ['reg:squarederror', 'reg:pseudohubererror']\n",
    "    #'xgbreg__max_depth': [3, 4],\n",
    "    #'xgbreg__min_child_weight': [1, 3, 5, 7]\n",
    "}\n",
    "\n",
    "raw_adr_train = raw_train_df[adr_featureCols]\n",
    "gs = GridSearchCV(xgbreg_pipe, param_grid, cv=kf, n_jobs=4)\n",
    "gs.fit(raw_adr_train, raw_train_df['adr'])\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)\n",
    "\n",
    "# Getting all the grid search results in a Pandas DataFrame\n",
    "print(pd.DataFrame(gs.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.0436366032985"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df['adr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Predict is_canceled by soft logistic regression\n",
    "# Determine features\n",
    "isc_numericCols = ['lead_time', 'arrival_date_year', 'stays', 'stays_in_weekend_nights', 'stays_in_week_nights',\\\n",
    "               'adults', 'children', 'babies', 'persons', 'previous_cancellations',\\\n",
    "               'previous_bookings_not_canceled', 'booking_changes', 'days_in_waiting_list',\\\n",
    "               'required_car_parking_spaces', 'total_of_special_requests'\n",
    "              ]\n",
    "isc_categoricCols = ['hotel', 'arrival_date_month',\\\n",
    "                'arrival_date_week_number', 'arrival_date_day_of_month', 'meal',\\\n",
    "                'country', 'market_segment', 'distribution_channel',\\\n",
    "                'is_repeated_guest', 'reserved_room_type', 'assigned_room_type',\\\n",
    "                'deposit_type', 'customer_type', 'company', 'agent'\n",
    "               ]\n",
    "isc_featureCols = isc_numericCols + isc_categoricCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_train = train_df[isc_featureCols]\n",
    "isc_val = val_df[isc_featureCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining both categorical and numerical column transformations\n",
    "isc_ct = ColumnTransformer(transformers=[('cat', cat_pipe, isc_categoricCols), ('num', num_pipe, isc_numericCols)])\n",
    "isc_train_transformed = isc_ct.fit_transform(isc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "isc_sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "isc_svd = TruncatedSVD(n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Logostic regression\n",
    "logistic = LogisticRegression(penalty='l2', C=90.0, max_iter=10000)\n",
    "\n",
    "# Build pipeline\n",
    "logistic_pipe = Pipeline([('isc_transform', isc_ct), ('isc_svd', isc_svd), ('logistic', logistic)])\n",
    "\n",
    "# Decide sample weight\n",
    "sample_weights = train_df.apply(lambda row: pow(row.expected_cost, 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8288394089920808\n",
      "0.8304562737642586\n"
     ]
    }
   ],
   "source": [
    "# Execute pipeline\n",
    "logistic_pipe.fit(isc_train, train_df['is_canceled'], logistic__sample_weight=sample_weights)\n",
    "\n",
    "# Correlation coefficients\n",
    "print(logistic_pipe.score(isc_train, train_df['is_canceled']))\n",
    "print(logistic_pipe.score(isc_val, val_df['is_canceled']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting classifier\n",
    "gbc = GradientBoostingClassifier(validation_fraction=0.2, n_iter_no_change=10, tol=0.001, n_estimators=10000, random_state=1126)\n",
    "\n",
    "# Build pipeline\n",
    "gbc_pipe = Pipeline([('isc_transform', isc_ct), ('gbc', gbc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8783696287288979\n",
      "0.8785208557795906\n"
     ]
    }
   ],
   "source": [
    "# Execute pipeline\n",
    "gbc_pipe.fit(isc_train, train_df['is_canceled'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(gbc_pipe.score(isc_train, train_df['is_canceled']))\n",
    "print(gbc_pipe.score(isc_val, val_df['is_canceled']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "rfc = RandomForestClassifier(n_estimators=500, max_depth=None, max_features='sqrt', random_state=1126, n_jobs=4)\n",
    "rfc_pipe = Pipeline([('isc_transform', isc_ct), ('rfc', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9947412472561312\n",
      "0.8740572571956288\n"
     ]
    }
   ],
   "source": [
    "# Execute pipeline\n",
    "rfc_pipe.fit(isc_train, train_df['is_canceled'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(rfc_pipe.score(isc_train, train_df['is_canceled']))\n",
    "print(rfc_pipe.score(isc_val, val_df['is_canceled']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_canceled_proba(isc_model, X_df):\n",
    "    predicted_prob = isc_model.predict_proba(X_df)\n",
    "    will_be_canceled = np.empty(shape=predicted_prob.shape[0])\n",
    "    for i in range(will_be_canceled.shape[0]):\n",
    "        will_be_canceled[i] = predicted_prob[i][1]\n",
    "    return will_be_canceled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "def predict_daily_rank(isc_model, adr_model, X_df):\n",
    "    # Predict \"is_canceled\"\n",
    "    will_be_canceled = predict_canceled_proba(isc_model, X_df)\n",
    "    \n",
    "    # Predict \"adr\"\n",
    "    predicted_adr = adr_model.predict(X_df)\n",
    "       \n",
    "    # Predict revenue\n",
    "    predicted_revenue = predicted_adr * (1.0 - will_be_canceled) * (np.array(X_df['stays']))\n",
    "    X_df['predicted_revenue'] = pd.Series(predicted_revenue)\n",
    "    \n",
    "    # Aggregate by date\n",
    "    daily_df = X_df.groupby(['arrival_date']).agg({'predicted_revenue':'sum'})\n",
    "    \n",
    "    thresholds = [0, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000]\n",
    "    ranks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    daily_df['label'] = pd.cut(daily_df.predicted_revenue, bins=thresholds,labels=ranks)\n",
    "    daily_df.reset_index(drop=False, inplace=True)\n",
    "    \n",
    "    return daily_df[['arrival_date', 'label']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Make prediction on validation data\n",
    "daily_df = predict_daily_rank(rfc_pipe, gbreg_pipe, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = daily_df.set_index('arrival_date').join(raw_train_label_df.set_index('arrival_date'), lsuffix=\"_predicted\", rsuffix=\"_true\", how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['err'] = result_df.apply(lambda row: abs(row.label_predicted - row.label_true), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15625\n"
     ]
    }
   ],
   "source": [
    "total_error = result_df['err'].sum(axis = 0, skipna = True) / result_df.shape[0]\n",
    "print(total_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    153\n",
      "1.0     36\n",
      "3.0      2\n",
      "2.0      1\n",
      "Name: err, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(result_df['err'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2017-03-17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date label\n",
       "0     2015-07-03     1\n",
       "1     2015-07-05     2\n",
       "2     2015-07-06     2\n",
       "3     2015-07-07     1\n",
       "4     2015-07-10     2\n",
       "..           ...   ...\n",
       "187   2017-03-17     2\n",
       "188   2017-03-20     3\n",
       "189   2017-03-27     2\n",
       "190   2017-03-30     2\n",
       "191   2017-03-31     3\n",
       "\n",
       "[192 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('isc_transform',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('si',\n",
       "                                                                   SimpleImputer(fill_value='MISSING',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['hotel',\n",
       "                                                   'arrival_date_month',\n",
       "                                                   'arrival_date_week_number',\n",
       "                                                   'arrival_date_day_of_month',\n",
       "                                                   'meal', 'country',\n",
       "                                                   'market_segment',\n",
       "                                                   'distribution_channel',\n",
       "                                                   'is_repe...\n",
       "                                                   'arrival_date_year', 'stays',\n",
       "                                                   'stays_in_weekend_nights',\n",
       "                                                   'stays_in_week_nights',\n",
       "                                                   'adults', 'children',\n",
       "                                                   'babies', 'persons',\n",
       "                                                   'previous_cancellations',\n",
       "                                                   'previous_bookings_not_canceled',\n",
       "                                                   'booking_changes',\n",
       "                                                   'days_in_waiting_list',\n",
       "                                                   'required_car_parking_spaces',\n",
       "                                                   'total_of_special_requests'])])),\n",
       "                ('rfc',\n",
       "                 RandomForestClassifier(max_features='sqrt', n_estimators=500,\n",
       "                                        n_jobs=4, random_state=1126))])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model with all training data\n",
    "# Train is_canceled\n",
    "isc_raw_train = raw_train_df[isc_featureCols]\n",
    "#sample_weights = raw_train_df.apply(lambda row: pow(row.expected_cost, 1), axis=1)\n",
    "rfc_pipe.fit(isc_raw_train, raw_train_df['is_canceled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('adr_transform',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('si',\n",
       "                                                                   SimpleImputer(fill_value='MISSING',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['hotel',\n",
       "                                                   'arrival_date_month',\n",
       "                                                   'arrival_date_week_number',\n",
       "                                                   'arrival_date_day_of_month',\n",
       "                                                   'meal', 'country',\n",
       "                                                   'market_segment',\n",
       "                                                   'distribution_channel',\n",
       "                                                   'is_repe...\n",
       "                                                   'adults', 'children',\n",
       "                                                   'babies', 'persons',\n",
       "                                                   'previous_cancellations',\n",
       "                                                   'previous_bookings_not_canceled',\n",
       "                                                   'booking_changes',\n",
       "                                                   'days_in_waiting_list',\n",
       "                                                   'required_car_parking_spaces',\n",
       "                                                   'total_of_special_requests'])])),\n",
       "                ('gbreg',\n",
       "                 GradientBoostingRegressor(loss='huber', max_depth=4,\n",
       "                                           n_estimators=10000,\n",
       "                                           n_iter_no_change=5,\n",
       "                                           random_state=1126, tol=0.005,\n",
       "                                           validation_fraction=0.2))])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train adr\n",
    "#will_be_canceled = pd.Series(predict_canceled_proba(gbc_pipe, raw_train_df))\n",
    "#raw_train_df['will_be_canceled'] = will_be_canceled\n",
    "adr_raw_train = raw_train_df[adr_featureCols]\n",
    "gbreg_pipe.fit(adr_raw_train, raw_train_df['adr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "#will_be_canceled = pd.Series(predict_canceled_proba(gbc_pipe, test_df))\n",
    "#test_df['will_be_canceled'] = will_be_canceled\n",
    "prediction_df = predict_daily_rank(rfc_pipe, gbreg_pipe, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date label\n",
       "0     2017-04-01     3\n",
       "1     2017-04-02     2\n",
       "2     2017-04-03     3\n",
       "3     2017-04-04     1\n",
       "4     2017-04-05     3\n",
       "..           ...   ...\n",
       "148   2017-08-27     5\n",
       "149   2017-08-28     8\n",
       "150   2017-08-29     3\n",
       "151   2017-08-30     3\n",
       "152   2017-08-31     4\n",
       "\n",
       "[153 rows x 2 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    44\n",
       "4    41\n",
       "2    24\n",
       "5    18\n",
       "6    14\n",
       "7     7\n",
       "1     3\n",
       "9     1\n",
       "8     1\n",
       "0     0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 人肉7\n",
    "prediction_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv(\"prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbreg_pipe_10000_huber_oob-0.2_es-0.005-5_td-4.joblib']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save regression model\n",
    "dump(gbreg_pipe, 'gbreg_pipe_10000_huber_oob-0.2_es-0.005-5_td-4.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rfc_pipe_500_sqrt.joblib']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save classification medel\n",
    "dump(rfc_pipe, 'rfc_pipe_500_sqrt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "gbc_pipe = load('gbc_pipe_5000_oob-0.2_es-0.001-10.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbreg_pipe = load('gbreg_pipe_10000_huber_oob-0.2_es-0.005-5_td-4.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
