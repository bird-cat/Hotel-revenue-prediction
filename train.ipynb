{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, confusion_matrix, log_loss\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression, SGDRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost.sklearn import XGBRegressor, XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from joblib import dump, load\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "raw_train_df = pd.read_csv(\"train.csv\")\n",
    "raw_train_label_df = pd.read_csv('train_label.csv')\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation set and training set\n",
    "dates = raw_train_df.arrival_date.unique()\n",
    "train_indices, val_indices = train_test_split(dates, test_size=0.3)\n",
    "train_df = raw_train_df.set_index('arrival_date').loc[train_indices, :]\n",
    "val_df = raw_train_df.set_index('arrival_date').loc[val_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=False, inplace=True)\n",
    "val_df.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer\n",
    "\n",
    "# Transforming the categoric columns\n",
    "cat_si_step = ('si', SimpleImputer(strategy='constant', fill_value='MISSING'))\n",
    "cat_ohe_step = ('ohe', OneHotEncoder(sparse=True, handle_unknown='ignore'))\n",
    "cat_steps = [cat_si_step, cat_ohe_step]\n",
    "cat_pipe = Pipeline(cat_steps)\n",
    "\n",
    "# Transforming the numeric columns\n",
    "num_si_step = ('si', SimpleImputer(strategy='median'))\n",
    "num_ss_step = ('ss', StandardScaler())\n",
    "num_steps = [num_si_step, num_ss_step]\n",
    "num_pipe = Pipeline(num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Predict ADR by regression\n",
    "# Determine features\n",
    "adr_numericCols = ['lead_time', 'arrival_date_year', 'stays', 'stays_in_weekend_nights', 'stays_in_week_nights',\\\n",
    "               'adults', 'children', 'babies', 'persons', 'previous_cancellations',\\\n",
    "               'previous_bookings_not_canceled', 'booking_changes', 'days_in_waiting_list',\\\n",
    "               'required_car_parking_spaces', 'total_of_special_requests'\n",
    "              ]\n",
    "adr_categoricCols = ['hotel', 'arrival_date_month',\\\n",
    "                'arrival_date_week_number', 'arrival_date_day_of_month', 'meal',\\\n",
    "                'country', 'market_segment', 'distribution_channel',\\\n",
    "                'is_repeated_guest', 'reserved_room_type', 'assigned_room_type',\\\n",
    "                'deposit_type', 'customer_type', 'agent', 'company'\n",
    "               ]\n",
    "\n",
    "adr_featureCols = adr_numericCols + adr_categoricCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwill_be_canceled = predict_canceled_proba(gbc_pipe, train_df)\\ntrain_df['will_be_canceled'] = will_be_canceled\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "will_be_canceled = predict_canceled_proba(gbc_pipe, train_df)\n",
    "train_df['will_be_canceled'] = will_be_canceled\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_train = train_df[adr_featureCols]\n",
    "adr_val = val_df[adr_featureCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining both categorical and numerical column transformations\n",
    "adr_ct = ColumnTransformer(transformers=[('cat', cat_pipe, adr_categoricCols), ('num', num_pipe, adr_numericCols)])\n",
    "adr_train_transformed = adr_ct.fit_transform(adr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features =  854\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the feature names\n",
    "cat_transformers = [('cat', cat_pipe, adr_categoricCols)]\n",
    "cat_ct = ColumnTransformer(transformers=cat_transformers)\n",
    "train_cat_transformed = cat_ct.fit_transform(train_df)\n",
    "\n",
    "num_transformers = [('num', num_pipe, adr_numericCols)]\n",
    "num_ct = ColumnTransformer(transformers=num_transformers)\n",
    "train_num_transformed = num_ct.fit_transform(train_df)\n",
    "\n",
    "cat_pl = cat_ct.named_transformers_['cat']\n",
    "ohe = cat_pl.named_steps['ohe']\n",
    "transformed_feature_names = list(ohe.get_feature_names()) + adr_numericCols\n",
    "print(\"Total number of features = \", len(transformed_feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "adr_sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "adr_svd = TruncatedSVD(n_components=30) # best 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "ridge = Ridge(alpha=1.0/(2*100), max_iter=10000) # alpha = 1 / 2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# feature transformation\n",
    "poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Build ridge pipeline\n",
    "ridge_pipe = Pipeline([('adr_transform', adr_ct), ('adr_svd', adr_svd), ('poly', poly), ('ridge', ridge)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5396044840978833\n",
      "0.6039522121224565\n",
      "1224.477257650087\n",
      "794.8081163227173\n"
     ]
    }
   ],
   "source": [
    "# Execute ridge pipeline\n",
    "ridge_pipe.fit(adr_train, train_df['adr'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(ridge_pipe.score(adr_train, train_df['adr']))\n",
    "print(ridge_pipe.score(adr_val, val_df['adr']))\n",
    "\n",
    "# Mean squared errors\n",
    "print(mean_squared_error(ridge_pipe.predict(adr_train), train_df['adr']))\n",
    "print(mean_squared_error(ridge_pipe.predict(adr_val), val_df['adr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# SVR\n",
    "rbf_feature = Nystroem(gamma=10**(-1.5), n_components=600, random_state=1126)\n",
    "sgdreg = SGDRegressor(loss='epsilon_insensitive', alpha=10**(-11), max_iter=10000)\n",
    "\n",
    "sgd_pipe = Pipeline([('adr_transform', adr_ct), ('rbf', rbf_feature), ('sgdreg', sgdreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38272605380374847\n",
      "0.45698674243912296\n",
      "1591.1612936139725\n",
      "1179.9846833209801\n"
     ]
    }
   ],
   "source": [
    "# Execute svr pipeline\n",
    "sgd_pipe.fit(adr_train, train_df['adr'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(sgd_pipe.score(adr_train, train_df['adr']))\n",
    "print(sgd_pipe.score(adr_val, val_df['adr']))\n",
    "\n",
    "# Mean squared errors\n",
    "print(mean_squared_error(sgd_pipe.predict(adr_train), train_df['adr']))\n",
    "print(mean_squared_error(sgd_pipe.predict(adr_val), val_df['adr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting regressor\n",
    "gbreg = GradientBoostingRegressor(loss='huber',\n",
    "                                  alpha=0.9,\n",
    "                                  validation_fraction=0.2,\n",
    "                                  n_iter_no_change=5,\n",
    "                                  tol=0.005,\n",
    "                                  max_depth=4,\n",
    "                                  n_estimators=10000,\n",
    "                                  random_state=1126,\n",
    "                                  warm_start=False,\n",
    "                                  verbose=True)\n",
    "gbreg_pipe = Pipeline([('adr_transform', adr_ct), ('gbreg', gbreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1         973.2872           28.69m\n",
      "         2         927.4869           26.89m\n",
      "         3         876.2162           26.52m\n",
      "         4         825.3887           25.87m\n",
      "         5         789.1283           25.80m\n",
      "         6         759.0266           25.55m\n",
      "         7         737.2141           25.37m\n",
      "         8         707.6285           25.20m\n",
      "         9         679.5077           25.36m\n",
      "        10         658.5888           25.59m\n",
      "        20         524.2881           25.62m\n",
      "        30         446.7734           25.32m\n",
      "        40         399.5543           24.76m\n",
      "        50         368.1456           24.48m\n",
      "        60         338.6124           24.24m\n",
      "        70         314.8602           24.20m\n",
      "        80         295.5711           24.11m\n",
      "        90         279.7047           23.94m\n",
      "       100         269.0907           23.73m\n",
      "       200         204.2607           22.61m\n",
      "       300         181.2113           21.80m\n",
      "       400         167.7369           21.30m\n",
      "       500         158.4663           20.86m\n",
      "       600         151.6005           20.49m\n",
      "       700         146.7685           20.16m\n",
      "       800         142.3398           19.90m\n",
      "       900         138.9153           19.66m\n",
      "      1000         136.3244           19.36m\n",
      "0.7054803246673251\n",
      "0.7994599516329404\n",
      "783.3105056827286\n",
      "402.45360021849774\n"
     ]
    }
   ],
   "source": [
    "# Execute gradient boosting pipeline\n",
    "gbreg_pipe.fit(adr_train, train_df['adr'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(gbreg_pipe.score(adr_train, train_df['adr']))\n",
    "print(gbreg_pipe.score(adr_val, val_df['adr']))\n",
    "\n",
    "# Mean squared errors\n",
    "print(mean_squared_error(gbreg_pipe.predict(adr_train), train_df['adr']))\n",
    "print(mean_squared_error(gbreg_pipe.predict(adr_val), val_df['adr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost regressor\n",
    "xgbreg = XGBRegressor(booster='gbtree',\n",
    "                      objective='reg:pseudohubererror',\n",
    "                      learning_rate=0.01,\n",
    "                      n_estimators=20000,\n",
    "                      min_child_weight=1,\n",
    "                      subsample=0.6,\n",
    "                      colsample_bytree=0.8, # best\n",
    "                      max_depth=6,\n",
    "                      gamma=0.0,\n",
    "                      random_state=1126)\n",
    "xgbreg_pipe = Pipeline([('adr_transform', adr_ct), ('xgbreg', xgbreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7169984567844712\n",
      "0.8172273522999641\n",
      "752.6766477477331\n",
      "366.79710954148254\n"
     ]
    }
   ],
   "source": [
    "# Execute gradient boosting pipeline\n",
    "xgbreg_pipe.fit(adr_train, train_df['adr'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(xgbreg_pipe.score(adr_train, train_df['adr']))\n",
    "print(xgbreg_pipe.score(adr_val, val_df['adr']))\n",
    "\n",
    "# Mean squared errors\n",
    "print(mean_squared_error(xgbreg_pipe.predict(adr_train), train_df['adr']))\n",
    "print(mean_squared_error(xgbreg_pipe.predict(adr_val), val_df['adr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-c7a886380b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mraw_adr_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_train_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madr_featureCols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgbreg_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_adr_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_train_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cross-Validation\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=1126)\n",
    "\n",
    "# Selecting parameters when Grid Searching\n",
    "param_grid = {\n",
    "    'xgbreg__n_estimators': [1000, 3000, 5000],\n",
    "    #'xgbreg__objective': ['reg:squarederror', 'reg:pseudohubererror']\n",
    "    #'xgbreg__max_depth': [3, 4],\n",
    "    #'xgbreg__min_child_weight': [1, 3, 5, 7]\n",
    "}\n",
    "\n",
    "raw_adr_train = raw_train_df[adr_featureCols]\n",
    "gs = GridSearchCV(xgbreg_pipe, param_grid, cv=kf, n_jobs=4)\n",
    "gs.fit(raw_adr_train, raw_train_df['adr'])\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)\n",
    "\n",
    "# Getting all the grid search results in a Pandas DataFrame\n",
    "print(pd.DataFrame(gs.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.0436366032985"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df['adr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Predict is_canceled by soft logistic regression\n",
    "# Determine features\n",
    "isc_numericCols = ['lead_time', 'arrival_date_year', 'stays', 'stays_in_weekend_nights', 'stays_in_week_nights',\\\n",
    "               'adults', 'children', 'babies', 'persons', 'previous_cancellations',\\\n",
    "               'previous_bookings_not_canceled', 'booking_changes', 'days_in_waiting_list',\\\n",
    "               'required_car_parking_spaces', 'total_of_special_requests'\n",
    "              ]\n",
    "isc_categoricCols = ['hotel', 'arrival_date_month',\\\n",
    "                'arrival_date_week_number', 'arrival_date_day_of_month', 'meal',\\\n",
    "                'country', 'market_segment', 'distribution_channel',\\\n",
    "                'is_repeated_guest', 'reserved_room_type', 'assigned_room_type',\\\n",
    "                'deposit_type', 'customer_type', 'company', 'agent'\n",
    "               ]\n",
    "isc_featureCols = isc_numericCols + isc_categoricCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc_train = train_df[isc_featureCols]\n",
    "isc_val = val_df[isc_featureCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining both categorical and numerical column transformations\n",
    "isc_ct = ColumnTransformer(transformers=[('cat', cat_pipe, isc_categoricCols), ('num', num_pipe, isc_numericCols)])\n",
    "isc_train_transformed = isc_ct.fit_transform(isc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "isc_sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "isc_svd = TruncatedSVD(n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Logostic regression\n",
    "logistic = LogisticRegression(penalty='l2', C=90.0, max_iter=10000)\n",
    "\n",
    "# Build pipeline\n",
    "logistic_pipe = Pipeline([('isc_transform', isc_ct), ('isc_svd', isc_svd), ('logistic', logistic)])\n",
    "\n",
    "# Decide sample weight\n",
    "sample_weights = train_df.apply(lambda row: pow(row.expected_cost, 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8288394089920808\n",
      "0.8304562737642586\n"
     ]
    }
   ],
   "source": [
    "# Execute pipeline\n",
    "logistic_pipe.fit(isc_train, train_df['is_canceled'], logistic__sample_weight=sample_weights)\n",
    "\n",
    "# Correlation coefficients\n",
    "print(logistic_pipe.score(isc_train, train_df['is_canceled']))\n",
    "print(logistic_pipe.score(isc_val, val_df['is_canceled']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting classifier\n",
    "gbc = GradientBoostingClassifier(validation_fraction=0.2, n_iter_no_change=10, tol=0.001, n_estimators=10000, random_state=1126)\n",
    "\n",
    "# Build pipeline\n",
    "gbc_pipe = Pipeline([('isc_transform', isc_ct), ('gbc', gbc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8816451120571933\n",
      "0.8654030887460282\n"
     ]
    }
   ],
   "source": [
    "# Execute pipeline\n",
    "gbc_pipe.fit(isc_train, train_df['is_canceled'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(gbc_pipe.score(isc_train, train_df['is_canceled']))\n",
    "print(gbc_pipe.score(isc_val, val_df['is_canceled']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "rfc = RandomForestClassifier(n_estimators=500, max_depth=None, max_features='sqrt', random_state=1126, n_jobs=4)\n",
    "rfc_pipe = Pipeline([('isc_transform', isc_ct), ('rfc', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9946019760623344\n",
      "0.8707603635557526\n"
     ]
    }
   ],
   "source": [
    "# Execute pipeline\n",
    "rfc_pipe.fit(isc_train, train_df['is_canceled'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(rfc_pipe.score(isc_train, train_df['is_canceled']))\n",
    "print(rfc_pipe.score(isc_val, val_df['is_canceled']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost classifier\n",
    "xgbc = XGBClassifier(booster='gbtree',\n",
    "                     objective='binary:logistic',\n",
    "                     learning_rate=0.01,\n",
    "                     n_estimators=20000,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8, # best\n",
    "                     max_depth=6,\n",
    "                     gamma=0.0,\n",
    "                     random_state=1126)\n",
    "xgbc_pipe = Pipeline([('adr_transform', adr_ct), ('xgbc', xgbc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "std::bad_alloc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-de6924031946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Execute gradient boosting pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgbc_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madr_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Correlation coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgbc_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madr_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    917\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    212\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1280\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: std::bad_alloc"
     ]
    }
   ],
   "source": [
    "# Execute gradient boosting pipeline\n",
    "xgbc_pipe.fit(adr_train, train_df['adr'])\n",
    "\n",
    "# Correlation coefficients\n",
    "print(xgbc_pipe.score(adr_train, train_df['adr']))\n",
    "print(xgbc_pipe.score(adr_val, val_df['adr']))\n",
    "\n",
    "# Mean squared errors\n",
    "print(mean_squared_error(xgbc_pipe.predict(adr_train), train_df['adr']))\n",
    "print(mean_squared_error(xgbc_pipe.predict(adr_val), val_df['adr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_canceled_proba(isc_model, X_df):\n",
    "    predicted_prob = isc_model.predict_proba(X_df)\n",
    "    will_be_canceled = np.empty(shape=predicted_prob.shape[0])\n",
    "    for i in range(will_be_canceled.shape[0]):\n",
    "        will_be_canceled[i] = predicted_prob[i][1]\n",
    "    return will_be_canceled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "def predict_daily_rank(isc_model, adr_model, X_df):\n",
    "    # Predict \"is_canceled\"\n",
    "    will_be_canceled = predict_canceled_proba(isc_model, X_df)\n",
    "    \n",
    "    # Predict \"adr\"\n",
    "    predicted_adr = adr_model.predict(X_df)\n",
    "       \n",
    "    # Predict revenue\n",
    "    predicted_revenue = predicted_adr * (1.0 - will_be_canceled) * (np.array(X_df['stays']))\n",
    "    X_df['predicted_revenue'] = pd.Series(predicted_revenue)\n",
    "    \n",
    "    # Aggregate by date\n",
    "    daily_df = X_df.groupby(['arrival_date']).agg({'predicted_revenue':'sum'})\n",
    "    \n",
    "    thresholds = [0, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000]\n",
    "    ranks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    daily_df['label'] = pd.cut(daily_df.predicted_revenue, bins=thresholds,labels=ranks)\n",
    "    daily_df.reset_index(drop=False, inplace=True)\n",
    "    \n",
    "    return daily_df[['arrival_date', 'label']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Make prediction on validation data\n",
    "daily_df = predict_daily_rank(rfc_pipe, xgbreg_pipe, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = daily_df.set_index('arrival_date').join(raw_train_label_df.set_index('arrival_date'), lsuffix=\"_predicted\", rsuffix=\"_true\", how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['err'] = result_df.apply(lambda row: abs(row.label_predicted - row.label_true), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20833333333333334\n"
     ]
    }
   ],
   "source": [
    "total_error = result_df['err'].sum(axis = 0, skipna = True) / result_df.shape[0]\n",
    "print(total_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    152\n",
      "1.0     40\n",
      "Name: err, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(result_df['err'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2017-03-17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date label\n",
       "0     2015-07-03     1\n",
       "1     2015-07-05     2\n",
       "2     2015-07-06     2\n",
       "3     2015-07-07     1\n",
       "4     2015-07-10     2\n",
       "..           ...   ...\n",
       "187   2017-03-17     2\n",
       "188   2017-03-20     3\n",
       "189   2017-03-27     2\n",
       "190   2017-03-30     2\n",
       "191   2017-03-31     3\n",
       "\n",
       "[192 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('isc_transform',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('si',\n",
       "                                                                   SimpleImputer(fill_value='MISSING',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['hotel',\n",
       "                                                   'arrival_date_month',\n",
       "                                                   'arrival_date_week_number',\n",
       "                                                   'arrival_date_day_of_month',\n",
       "                                                   'meal', 'country',\n",
       "                                                   'market_segment',\n",
       "                                                   'distribution_channel',\n",
       "                                                   'is_repe...\n",
       "                                                   'arrival_date_year', 'stays',\n",
       "                                                   'stays_in_weekend_nights',\n",
       "                                                   'stays_in_week_nights',\n",
       "                                                   'adults', 'children',\n",
       "                                                   'babies', 'persons',\n",
       "                                                   'previous_cancellations',\n",
       "                                                   'previous_bookings_not_canceled',\n",
       "                                                   'booking_changes',\n",
       "                                                   'days_in_waiting_list',\n",
       "                                                   'required_car_parking_spaces',\n",
       "                                                   'total_of_special_requests'])])),\n",
       "                ('rfc',\n",
       "                 RandomForestClassifier(max_features='sqrt', n_estimators=500,\n",
       "                                        n_jobs=4, random_state=1126))])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model with all training data\n",
    "# Train is_canceled\n",
    "isc_raw_train = raw_train_df[isc_featureCols]\n",
    "#sample_weights = raw_train_df.apply(lambda row: pow(row.expected_cost, 1), axis=1)\n",
    "rfc_pipe.fit(isc_raw_train, raw_train_df['is_canceled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('adr_transform',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('si',\n",
       "                                                                   SimpleImputer(fill_value='MISSING',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['hotel',\n",
       "                                                   'arrival_date_month',\n",
       "                                                   'arrival_date_week_number',\n",
       "                                                   'arrival_date_day_of_month',\n",
       "                                                   'meal', 'country',\n",
       "                                                   'market_segment',\n",
       "                                                   'distribution_channel',\n",
       "                                                   'is_repe...\n",
       "                              importance_type='gain',\n",
       "                              interaction_constraints='', learning_rate=0.01,\n",
       "                              max_delta_step=0, max_depth=6, min_child_weight=1,\n",
       "                              missing=nan, monotone_constraints='()',\n",
       "                              n_estimators=20000, n_jobs=4, num_parallel_tree=1,\n",
       "                              objective='reg:pseudohubererror',\n",
       "                              random_state=1126, reg_alpha=0, reg_lambda=1,\n",
       "                              scale_pos_weight=1, subsample=0.8,\n",
       "                              tree_method='exact', validate_parameters=1,\n",
       "                              verbosity=None))])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train adr\n",
    "#will_be_canceled = pd.Series(predict_canceled_proba(gbc_pipe, raw_train_df))\n",
    "#raw_train_df['will_be_canceled'] = will_be_canceled\n",
    "adr_raw_train = raw_train_df[adr_featureCols]\n",
    "xgbreg_pipe.fit(adr_raw_train, raw_train_df['adr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Make prediction on test data\n",
    "#will_be_canceled = pd.Series(predict_canceled_proba(gbc_pipe, test_df))\n",
    "#test_df['will_be_canceled'] = will_be_canceled\n",
    "prediction_df = predict_daily_rank(rfc_pipe, xgbreg_pipe, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date label\n",
       "0     2017-04-01     3\n",
       "1     2017-04-02     2\n",
       "2     2017-04-03     4\n",
       "3     2017-04-04     1\n",
       "4     2017-04-05     3\n",
       "..           ...   ...\n",
       "148   2017-08-27     5\n",
       "149   2017-08-28     8\n",
       "150   2017-08-29     3\n",
       "151   2017-08-30     3\n",
       "152   2017-08-31     4\n",
       "\n",
       "[153 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    46\n",
       "3    35\n",
       "2    23\n",
       "5    22\n",
       "6    13\n",
       "7     9\n",
       "1     3\n",
       "9     1\n",
       "8     1\n",
       "0     0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7\n",
    "prediction_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv(\"prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgbreg_pipe_20000_huber_lr-0.01_td-6_mcw-1_ss-0.8_cs-0.8_gamma-0.01.joblib']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save regression model\n",
    "dump(xgbreg_pipe, 'xgbreg_pipe_20000_huber_lr-0.01_td-6_mcw-1_ss-0.8_cs-0.8_gamma-0.01.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rfc_pipe_500_sqrt.joblib']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save classification medel\n",
    "dump(rfc_pipe, 'rfc_pipe_500_sqrt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "rfc_pipe = load('rfc_pipe_500_sqrt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbreg_pipe = load('gbreg_pipe_10000_huber_oob-0.2_es-0.005-5_td-4.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
